{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No notebook anterior, nós aprendemos intuitivamente como o perceptron aprende. De maneira geral, nós vamos atualizando os pesos e o bias sempre buscando diminuir uma função de custo. Nesse notebook, nós vamos ver como esse aprendizado realmente acontence, tanto na teoria quanto na prática. Também utilizaremos o Perceptron para resolver problemas de classificação e regressão.\n",
    "\n",
    "__Objetivos__:\n",
    "\n",
    "- Implementar o perceptron e seu modelo de aprendizado em python puro e numpy\n",
    "- Utilizar o perceptron para regressão e classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Introdução](#Introdução)\n",
    "- [Regra de Aprendizado do Perceptron](#Regra-de-Aprendizado-do-Perceptron)\n",
    "- [Pseudo-algoritmo do Perceptron](#Pseudo-algoritmo-do-Perceptron)\n",
    "\n",
    "[Classificação](#Classificação)\n",
    "- [Porta AND/OR](#Porta-AND/OR)\n",
    "- [Exercício de Classificação](#Exerc%C3%ADcio-de-Classificação)\n",
    "\n",
    "[Regressão](#Regressão)\n",
    "- [Exercício de Regressão](#Exerc%C3%ADcio-de-Regressão)\n",
    "\n",
    "[Referências](#Referências)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:53:30.345746Z",
     "start_time": "2017-09-20T12:52:48.057739Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "O tipo mais básico de Rede Neural Artificial é formada por apenas um neurônio, o __Perceptron__. Inicialmente, o Perceptron foi projetado para ser um __classificador binário linear__ responsável por mapear uma ou mais entradas em uma saída desejada. Porém, também podemos utilizá-lo para resolver problemas de __regressão linear__. Ele foi projetado em 1957 por Frank Rosenblatt.\n",
    "\n",
    "O perceptron é formado por:\n",
    "\n",
    "<img src='images/perceptron.png' width='350'>\n",
    "\n",
    "- __entradas__ $x_1 ... x_D$: representam os atributos dos seus dados com dimensionalidade $D$. O Perceptron aceita qualquer tamanho de entrada, porém a saída é sempre apenas um valor.\n",
    "- __junção aditiva__ $\\sum$: também chamada de _função agregadora_, nada mais é que a soma ponderada das entradas com os __pesos__ ($w_1 ... w_D)$. Em geral, o resultado é somado com um __bias__ $b$, responsável por deslocar o resultado do somatório. A junção aditiva é descrita pela seguinte fórmula:\n",
    "\n",
    "$$\\sum_i^D{x_iw_i} + b$$\n",
    "\n",
    "- __função de ativação__ $f$: utilizada para mapear o resultado da junção aditiva em uma saída esperada. Mais detalhes abaixo.\n",
    "\n",
    "Logo, o Perceptron é representado pela seguinte fórmula matemática:\n",
    "\n",
    "$$y_{pred_i} = f(\\sum_i^D{x_iw_i} + b)$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "- $D$: representa a dimensionalidade das amostras, ou seja, a quantidade de atributos de cada amostra.\n",
    "- $x_i$: representam os atributos dos nossos dados que servem de entrada para o Perceptron.\n",
    "- $w_i$: representam os __pesos sinápticos__ que ponderam as entradas.\n",
    "- $b$: representa o __bias__, responsável por deslocar a fronteira de decisão além da origem e não depende de nenhum valor de entrada. Repare que o bias encontra-se fora do somatório.\n",
    "- $f$: __função de ativação__. Quando a função de ativação é linear, ou seja, nenhuma transformação é aplicada no resultado da junção aditiva, o Perceptron atua como um __Regressor Linear__. Se precisamos efetuar uma __Classificação binária__, devemos utilizar a função _step_ (também conhecida como _função degrau_) para mapear a saída em um valor discreto (0 ou 1):\n",
    "\n",
    "$$y_{pred} = \\begin{cases}1 & se \\ wx+b > 0\\\\0 & caso \\ contr\\acute ario\\end{cases}$$\n",
    "\n",
    "- $y_{pred}$: representa a saída do Perceptron (o valor predito).\n",
    "\n",
    "__Observações importantes__:\n",
    "\n",
    "- O Perceptron não faz __Classificação Multiclasse__.\n",
    "- __A atualização dos pesos é *online*, ou seja, efetuada amostra a amostra__ utilizando uma fórmula pré-definida que veremos na seção a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regra de Aprendizado do Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Perceptron tem sua própria forma de aprendizado conforme definido no seu artigo original. Na verdade, a fórmula para atualização dos pesos e bias é bem simples:\n",
    "\n",
    "$$w_i = w_i + \\lambda(y_i - y_{pred_i})x_i$$\n",
    "$$b_i = b_i + \\lambda(y_i - y_{pred_i})$$\n",
    "\n",
    "Onde $\\lambda$ é a __taxa de aprendizagem__.\n",
    "\n",
    "Repare que $y_i - y_{pred_i}$ significa calcular a diferença entre o valor esperado ($y_i$) e o valor predito ($y_{pred_i}$). Supondo que estamos fazendo __classificação binária__ de uma amostra $(x_i, y_i)$. Nesse caso, teremos duas possibilidades:\n",
    "- __O valor esperado é $y_i = y_{pred_i}$__, ou seja, a saída do Perceptron (após a função de ativação _step_) é __igual__ a saída esperada. Nesse caso, __a diferença $y_i - y_{pred_i} = 0$ e não haverá atualização de pesos__.\n",
    "- __O valor esperado é $y_i \\neq y_{pred_i}$__, ou seja, a saída do Perceptron (após a função de ativação _step_) é __diferente__ da saída esperada. Nesse caso, __a atualização dos pesos será dada pela diferença $y_i - y_{pred_i}$__. Repare que:\n",
    "    - quando essa diferença é __negativa__ (ou seja, $y_i = 0$ e $y_{pred_i} = 1$), __os pesos tendem a diminuir__.\n",
    "    - quando essa diferença é __positiva__ (ou seja, $y_i = 1$ e $y_{pred_i} = 0$), __os pesos tendem a aumentar__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo-algoritmo do Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inicialize os pesos $w_i$ e o bias _$b$\n",
    "2. Para cada amostra $(x_i, y_i)$ do nosso banco:\n",
    "    1. Calcule $y_{pred_i} = f(\\sum_i^D{x_iw_i} + b)$, onde $f$ é a __função _step_ para classificação__ e __linear no caso da regressão__\n",
    "    2. Calcule o $erro = y_i - y_{pred_i}$\n",
    "    3. Atualize os pesos $w_i = w_i + \\lambda*erro*x_i$\n",
    "    4. Atualize o bias $b_i = b_i + \\lambda*erro$\n",
    "3. Repita o passo 2 por N vezes ou até que alguma medida de custo para o $erro$ seja menor que um valor pré-determinado pelo usuário\n",
    "    \n",
    "Repare, como dito lá em cima, que __a atualização dos pesos e bias é feito a cada amostra__, e não somente após ver todas as amostras do banco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porta AND/OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T11:11:37.370366Z",
     "start_time": "2017-09-15T11:11:37.359356Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2) (4, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "#y = np.array([0, 1, 1, 1]) # porta OR\n",
    "y = np.array([[0, 0, 0, 1]]).T # porta AND\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T11:21:18.798586Z",
     "start_time": "2017-09-15T11:21:18.667487Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D = x.shape[1]\n",
    "w = [2*random() - 1 for i in range(D)] # [1xD]\n",
    "b = 2*random() - 1 # [1x1]\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "for step in range(101):\n",
    "    cost = 0\n",
    "    for x_i, y_i in zip(x, y):\n",
    "        # insira seu código aqui!\n",
    "        \n",
    "    if step%10 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "\n",
    "print('w: ', w)\n",
    "print('b: ', b)\n",
    "print('y_pred: {0}'.format(np.dot(x, np.array(w))+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T12:21:02.603975Z",
     "start_time": "2017-09-15T12:21:02.555936Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D = x.shape[1]\n",
    "w = 2*np.random.random((1, D))-1\n",
    "b = 2*np.random.random()-1       \n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "for step in range(100):\n",
    "    cost = 0\n",
    "    for x_i, y_i in zip(x, y):\n",
    "        # insira seu código aqui!\n",
    "    \n",
    "    if step%10 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "    \n",
    "print('w: ', w)\n",
    "print('b: ', b)\n",
    "print('y_pred: {0}'.format(np.dot(w, x.T)+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercício de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = make_blobs(n_samples=100, n_features=2, centers=2, random_state=1234)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "plt.scatter(x[:,0], x[:,1], c=y, cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_linear_classifier(x, y, w, b):\n",
    "    x1_min, x1_max = x[:,0].min(), x[:,0].max()\n",
    "    x2_min, x2_max = x[:,1].min(), x[:,1].max()\n",
    "\n",
    "    x1, x2 = np.meshgrid(np.linspace(x1_min-1, x1_max+1,100), np.linspace(x2_min-1, x2_max+1, 100))\n",
    "    x_mesh = np.array([x1.ravel(), x2.ravel()]).T\n",
    "\n",
    "    plt.scatter(x[:,0], x[:,1], c=y, cmap='bwr')\n",
    "\n",
    "    y_mesh = np.dot(x_mesh, w.T) + b\n",
    "    y_mesh = np.where(y_mesh <= 0, 0, 1)\n",
    "\n",
    "    plt.contourf(x1, x2, y_mesh.reshape(x1.shape), cmap='bwr', alpha=0.5)\n",
    "    plt.xlim(x1_min-1, x1_max+1)\n",
    "    plt.ylim(x2_min-1, x2_max+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = x.shape[1]\n",
    "w = [2*random() - 1 for i in range(D)] # [1xD]\n",
    "b = 2*random() - 1 # [1x1]\n",
    "\n",
    "learning_rate = 1.0 # <- tente estimar a learning_rate\n",
    "\n",
    "for step in range(1001):\n",
    "    cost = 0\n",
    "    for x_i, y_i in zip(x, y):\n",
    "        y_pred = sum([w[d]*x_i[d] for d in range(D)]) + b\n",
    "        y_pred = 1 if y_pred > 0 else 0\n",
    "        error = y_i[0] - y_pred\n",
    "        w = [w[d] + learning_rate*error*x_i[d] for d in range(D)]\n",
    "        b = b + learning_rate*error\n",
    "        cost += error**2\n",
    "        \n",
    "    if step%100 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "\n",
    "print('w: ', w)\n",
    "print('b: ', b)\n",
    "\n",
    "plot_linear_classifier(x, y, np.array(w), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = x.shape[1]\n",
    "w = 2*np.random.random((1, D))-1\n",
    "b = 2*np.random.random()-1       \n",
    "\n",
    "learning_rate = 1.0 # <- tente estimar a learning_rate\n",
    "\n",
    "for step in range(51):\n",
    "    cost = 0\n",
    "    for x_i, y_i in zip(x, y):\n",
    "        x_i = x_i.reshape(1, D)\n",
    "        y_pred = np.dot(x_i, w.T) + b \n",
    "        y_pred = np.where(y_pred > 0, 1, 0)\n",
    "        error = y_i - y_pred\n",
    "        w = w + learning_rate*np.dot(error.T, x_i)\n",
    "        b = b + learning_rate*error\n",
    "        cost += error**2\n",
    "    \n",
    "    if step%10 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "    \n",
    "print('w: ', w)\n",
    "print('b: ', b)\n",
    "\n",
    "plot_linear_classifier(x, y, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Regressão "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para transformar o Perceptron em um __regressor linear__, só o que temos de fazer é __remover a função de ativação _step___, transformando-a em uma função de ativação linear.\n",
    "\n",
    "Apesar dessa modificação, __a fórmula de atualização dos pesos não sofre nenhuma alteração__. \n",
    "\n",
    "Vamos, então, implementar nosso perceptron para regressão em Python e Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T19:21:04.802972Z",
     "start_time": "2017-09-14T19:21:04.773952Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/medidas.csv')\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T19:21:08.765341Z",
     "start_time": "2017-09-14T19:21:08.441110Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = df.Altura.values\n",
    "y = df.Peso.values\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Altura')\n",
    "plt.ylabel('Peso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T19:21:10.893855Z",
     "start_time": "2017-09-14T19:21:10.883847Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T19:21:11.535313Z",
     "start_time": "2017-09-14T19:21:11.527304Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = x.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Exercício__: tentar estimar as learning_rates de __w__ e __b__. __Por que elas devem ser diferentes?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T19:21:38.253347Z",
     "start_time": "2017-09-14T19:21:16.413722Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D = x.shape[1]\n",
    "w = 2*random() - 1 # [1xD]\n",
    "b = 2*random() - 1 # [1x1]\n",
    "\n",
    "for step in range(10001):\n",
    "    cost = 0\n",
    "    # qual linha devemos remover para transformar o Perceptron num regressor?\n",
    "    for x_i, y_i in zip(x, y): \n",
    "        y_pred = x_i*w + b\n",
    "        y_pred = 1 if y_pred > 0 else 0\n",
    "        error = y_i[0] - y_pred\n",
    "        w = w + 1.0*error*x_i \n",
    "        b = b + 1.0*error     \n",
    "        cost += error**2\n",
    "\n",
    "    if step%1000 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "\n",
    "print('w: ', w)\n",
    "print('b: ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T19:21:45.406815Z",
     "start_time": "2017-09-14T19:21:45.008532Z"
    },
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: [[1.50243337]]\n",
      "step 1000: [[1000778.4382198]]\n",
      "step 2000: [[4001554.72571249]]\n",
      "step 3000: [[9002331.01320518]]\n",
      "step 4000: [[16003107.30069787]]\n",
      "step 5000: [[25003883.58819056]]\n",
      "step 6000: [[36004659.87568325]]\n",
      "step 7000: [[49005436.16317593]]\n",
      "step 8000: [[64006212.45066863]]\n",
      "step 9000: [[81006988.7381613]]\n",
      "step 10000: [[1.00007765e+08]]\n",
      "w:  [[10001.39302706  5001.19163022]]\n",
      "b:  [[-4999.20139684]]\n"
     ]
    }
   ],
   "source": [
    "D = x.shape[1]\n",
    "w = 2*np.random.random((1, D))-1 # [1xD]\n",
    "b = 2*np.random.random()-1       # [1x1]\n",
    "\n",
    "for step in range(10001):\n",
    "    cost = 0\n",
    "    for x_i, y_i in zip(x, y):\n",
    "        x_i = x_i.reshape(1, D)\n",
    "        y_pred = np.dot(x_i, w.T) + b \n",
    "        error = y_i - y_pred \n",
    "        w = w + 1.0*np.dot(error.T, x_i)\n",
    "        b = b + 1.0*error\n",
    "        cost += error**2\n",
    "    \n",
    "    if step%1000 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "    \n",
    "print('w: ', w)\n",
    "print('b: ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Numpy com Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T19:22:08.568244Z",
     "start_time": "2017-09-14T19:22:08.561239Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler(feature_range=(-1,1))\n",
    "x = minmax.fit_transform(x.astype(np.float64))\n",
    "\n",
    "print(x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(x,y)\n",
    "\n",
    "print('w: ', reg.coef_)\n",
    "print('b: ', reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T19:22:33.763665Z",
     "start_time": "2017-09-14T19:22:33.556518Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D = x.shape[1]\n",
    "w = 2*np.random.random((1, D))-1 # [1xD]\n",
    "b = 2*np.random.random()-1       # [1x1]\n",
    "\n",
    "learning_rate = 1.0 # <- tente estimar a learning_rate\n",
    "\n",
    "for step in range(1001):\n",
    "    cost = 0\n",
    "    for x_i, y_i in zip(x, y):\n",
    "        x_i = x_i.reshape(1, D)\n",
    "        y_pred = np.dot(x_i, w.T) + b\n",
    "        error = y_i - y_pred\n",
    "        w = w + learning_rate*np.dot(error.T, x_i)\n",
    "        b = b + learning_rate*error\n",
    "        cost += error**2\n",
    "    \n",
    "    if step%100 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "    \n",
    "print('w: ', w)\n",
    "print('b: ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Exercício de Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T10:56:07.079178Z",
     "start_time": "2017-09-15T10:56:06.991114Z"
    },
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prova1</th>\n",
       "      <th>prova2</th>\n",
       "      <th>prova3</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "      <td>93</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>87</td>\n",
       "      <td>79</td>\n",
       "      <td>90</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>88</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prova1  prova2  prova3  final\n",
       "0      73      80      75    152\n",
       "1      93      88      93    185\n",
       "2      89      91      90    180\n",
       "3      96      98     100    196\n",
       "4      73      66      70    142\n",
       "5      53      46      55    101\n",
       "6      69      74      77    149\n",
       "7      47      56      60    115\n",
       "8      87      79      90    175\n",
       "9      79      70      88    164"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/notas.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11a77f470>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABmQAAAF5CAYAAACBaEXmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSZIkSdKQ/T8IeGiXgLTdwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a57a278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(df.prova1.values, df.final.values)\n",
    "plt.xlabel('Prova 1')\n",
    "plt.ylabel('Final')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(df.prova2.values, df.final.values)\n",
    "plt.xlabel('Prova 2')\n",
    "plt.ylabel('Final')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(df.prova3.values, df.final.values)\n",
    "plt.xlabel('Prova 3')\n",
    "plt.ylabel('Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T10:56:14.202826Z",
     "start_time": "2017-09-15T10:56:14.189835Z"
    },
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3) (25, 1)\n"
     ]
    }
   ],
   "source": [
    "x = df[['prova1', 'prova2', 'prova3']].values\n",
    "y = df['final'].values.reshape(-1, 1)\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T10:56:15.149753Z",
     "start_time": "2017-09-15T10:56:15.143751Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler(feature_range=(-1,1))\n",
    "x = minmax.fit_transform(x.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T19:24:23.821886Z",
     "start_time": "2017-09-14T19:24:23.678784Z"
    },
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  [[ 8.72048636 14.1054877  26.26749487]]\n",
      "b:  [150.65175754]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasosouza/anaconda/envs/udacity/lib/python3.5/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(x,y)\n",
    "\n",
    "print('w: ', reg.coef_)\n",
    "print('b: ', reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T19:24:36.348182Z",
     "start_time": "2017-09-14T19:24:33.850407Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D = x.shape[1]\n",
    "w = [2*random() - 1 for d in range(D)] # [1xD]\n",
    "b = 2*random() - 1 # [1x1]\n",
    "\n",
    "learning_rate = 1.0 # <- tente estimar a learning_rate\n",
    "\n",
    "for step in range(2001):\n",
    "    cost = 0\n",
    "    for x_i, y_i in zip(x, y):\n",
    "        y_pred = sum([x_i[d]*w[d] for d in range(D)]) + b\n",
    "        error = y_i[0] - y_pred\n",
    "        w = [w[d] + learning_rate*error*x_i[d] for d in range(D)]\n",
    "        b = b + learning_rate*error\n",
    "        cost += error**2\n",
    "        \n",
    "    if step%200 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "\n",
    "print('w: ', w)\n",
    "print('b: ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T19:24:55.296538Z",
     "start_time": "2017-09-14T19:24:54.907259Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "D = x.shape[1]\n",
    "w = 2*np.random.random((1, D))-1\n",
    "b = 2*np.random.random()-1       \n",
    "\n",
    "learning_rate = 1.0 # <- use a mesma learning_rate do python\n",
    "\n",
    "for step in range(2001):\n",
    "    cost = 0\n",
    "    for x_i, y_i in zip(x, y):\n",
    "        x_i = x_i.reshape(1, D)\n",
    "        y_pred = np.dot(x_i, w.T) + b \n",
    "        error = y_i - y_pred\n",
    "        w = w + learning_rate*np.dot(error.T, x_i)\n",
    "        b = b + learning_rate*error\n",
    "        cost += error**2\n",
    "    \n",
    "    if step%200 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "    \n",
    "print('w: ', w)\n",
    "print('b: ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Artigo original do Perceptron](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.335.3398&rep=rep1&type=pdf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
